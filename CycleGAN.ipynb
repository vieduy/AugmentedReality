{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vieduy/AugmentedReality/blob/main/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VIGyIus8Vr7"
      },
      "source": [
        "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRm-USlsHgEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c954ac03-bcb8-4f36-a809-35f316990093"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 2337, done.\u001b[K\n",
            "remote: Total 2337 (delta 0), reused 0 (delta 0), pack-reused 2337\u001b[K\n",
            "Receiving objects: 100% (2337/2337), 8.09 MiB | 6.79 MiB/s, done.\n",
            "Resolving deltas: 100% (1499/1499), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1EySlOXwwoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6d3db9-e069-41c7-b245-eb17f4b9503f"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.9.1+cu101)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (22.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/55/f7c93bae36d869292aedfbcbae8b091386194874f16390d680136edd2b28/jsonpatch-1.32-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/23/52/05f67532aa922e494c351344e0d9624a01f74f5dd8402fe0d1b563a6e6fc/jsonpointer-2.1-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp37-none-any.whl size=655251 sha256=00d007b7ade0f362103ac9e7ada6924c49537509b305604d694a16118db26c51\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5712 sha256=1be2932d03350358441e494328e41dc850d16224ae99d4fa957b5a2e7e898943\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.6.0 jsonpatch-1.32 jsonpointer-2.1 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_cyclegan_dataset.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images.\n",
        "\n",
        "-   Create a dataset folder under `/dataset` for your dataset.\n",
        "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under your dataset's folder. Place any images you want to transform from a to b (cat2dog) in the `testA` folder, images you want to transform from b to a (dog2cat) in the `testB` folder, and do the same for the `trainA` and `trainB` folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdOettJxaCc"
      },
      "source": [
        "!bash ./datasets/download_cyclegan_dataset.sh vangogh2photo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "\n",
        "Download one of the official pretrained models with:\n",
        "\n",
        "-   `bash ./scripts/download_cyclegan_model.sh [apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower]`\n",
        "\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B75UqtKhxznS"
      },
      "source": [
        "!bash ./scripts/download_cyclegan_model.sh horse2zebra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/horse2zebra --name horse2zebra --model cycle_gan`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. I've found that a batch size of 16 fits onto 4 V100s and can finish training an epoch in ~90s.\n",
        "\n",
        "Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:\n",
        "\n",
        "Use `cp ./checkpoints/horse2zebra/latest_net_G_A.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class A to class B and `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` if you want to transform images from class B to class A.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d611e7a-b701-4f84-92e0-98b1d8c0506d"
      },
      "source": [
        "!python train.py --dataroot ./datasets/vangogh2photo --name vangogh2photo --model cycle_gan --continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: True                          \t[default: False]\n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/vangogh2photo      \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: vangogh2photo                 \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The number of training images = 6287\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "loading the model from ./checkpoints/vangogh2photo/latest_net_G_A.pth\n",
            "loading the model from ./checkpoints/vangogh2photo/latest_net_G_B.pth\n",
            "loading the model from ./checkpoints/vangogh2photo/latest_net_D_A.pth\n",
            "loading the model from ./checkpoints/vangogh2photo/latest_net_D_B.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1277, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1323, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1272, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1032, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 972, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdd4da3ba50>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdd4da3ba50>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 578, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdd4da3ba50>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/vangogh2photo/web...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "(epoch: 1, iters: 100, time: 1.421, data: 1.186) D_A: 0.168 G_A: 1.357 cycle_A: 1.946 idt_A: 0.474 D_B: 0.209 G_B: 0.515 cycle_B: 1.101 idt_B: 0.832 \n",
            "(epoch: 1, iters: 200, time: 1.416, data: 0.002) D_A: 0.030 G_A: 0.290 cycle_A: 2.381 idt_A: 0.441 D_B: 0.189 G_B: 0.941 cycle_B: 0.995 idt_B: 1.043 \n",
            "(epoch: 1, iters: 300, time: 1.415, data: 0.004) D_A: 0.109 G_A: 0.627 cycle_A: 3.316 idt_A: 0.463 D_B: 0.354 G_B: 0.559 cycle_B: 1.021 idt_B: 1.372 \n",
            "(epoch: 1, iters: 400, time: 7.005, data: 0.002) D_A: 0.045 G_A: 0.845 cycle_A: 5.828 idt_A: 0.489 D_B: 0.333 G_B: 0.534 cycle_B: 1.279 idt_B: 2.265 \n",
            "(epoch: 1, iters: 500, time: 1.412, data: 0.002) D_A: 0.026 G_A: 0.850 cycle_A: 4.849 idt_A: 0.450 D_B: 0.170 G_B: 0.190 cycle_B: 1.065 idt_B: 2.009 \n",
            "End of epoch 1 / 200 \t Time Taken: 672 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 2, iters: 100, time: 1.425, data: 0.566) D_A: 0.072 G_A: 1.035 cycle_A: 3.221 idt_A: 0.445 D_B: 0.092 G_B: 0.246 cycle_B: 1.081 idt_B: 1.977 \n",
            "(epoch: 2, iters: 200, time: 1.408, data: 0.002) D_A: 0.097 G_A: 0.693 cycle_A: 2.075 idt_A: 0.447 D_B: 0.420 G_B: 0.886 cycle_B: 1.197 idt_B: 1.190 \n",
            "(epoch: 2, iters: 300, time: 5.670, data: 0.002) D_A: 0.029 G_A: 0.778 cycle_A: 2.180 idt_A: 0.479 D_B: 0.137 G_B: 0.540 cycle_B: 1.094 idt_B: 0.938 \n",
            "(epoch: 2, iters: 400, time: 1.415, data: 0.002) D_A: 0.047 G_A: 0.853 cycle_A: 1.684 idt_A: 0.438 D_B: 0.108 G_B: 0.706 cycle_B: 1.015 idt_B: 0.704 \n",
            "(epoch: 2, iters: 500, time: 1.405, data: 0.002) D_A: 0.025 G_A: 0.923 cycle_A: 2.596 idt_A: 0.423 D_B: 0.199 G_B: 0.157 cycle_B: 0.960 idt_B: 1.064 \n",
            "End of epoch 2 / 200 \t Time Taken: 669 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 3, iters: 100, time: 1.411, data: 0.106) D_A: 0.022 G_A: 0.919 cycle_A: 3.791 idt_A: 0.452 D_B: 0.147 G_B: 0.301 cycle_B: 1.125 idt_B: 1.284 \n",
            "(epoch: 3, iters: 200, time: 5.790, data: 0.002) D_A: 0.040 G_A: 0.683 cycle_A: 1.744 idt_A: 0.450 D_B: 0.083 G_B: 0.427 cycle_B: 0.979 idt_B: 0.603 \n",
            "(epoch: 3, iters: 300, time: 1.407, data: 0.002) D_A: 0.061 G_A: 0.530 cycle_A: 2.445 idt_A: 0.428 D_B: 0.217 G_B: 0.433 cycle_B: 1.043 idt_B: 0.975 \n",
            "(epoch: 3, iters: 400, time: 1.404, data: 0.003) D_A: 0.035 G_A: 1.140 cycle_A: 1.652 idt_A: 0.437 D_B: 0.057 G_B: 0.244 cycle_B: 0.990 idt_B: 0.768 \n",
            "(epoch: 3, iters: 500, time: 1.395, data: 0.002) D_A: 0.042 G_A: 0.652 cycle_A: 2.140 idt_A: 0.414 D_B: 0.146 G_B: 0.128 cycle_B: 0.993 idt_B: 0.983 \n",
            "End of epoch 3 / 200 \t Time Taken: 667 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 4, iters: 100, time: 5.714, data: 0.608) D_A: 0.087 G_A: 0.514 cycle_A: 2.228 idt_A: 0.402 D_B: 0.088 G_B: 0.470 cycle_B: 0.963 idt_B: 0.986 \n",
            "(epoch: 4, iters: 200, time: 1.403, data: 0.002) D_A: 0.049 G_A: 0.815 cycle_A: 1.889 idt_A: 0.426 D_B: 0.129 G_B: 0.371 cycle_B: 0.994 idt_B: 0.730 \n",
            "(epoch: 4, iters: 300, time: 1.401, data: 0.002) D_A: 0.057 G_A: 0.571 cycle_A: 2.937 idt_A: 0.423 D_B: 0.199 G_B: 0.322 cycle_B: 1.058 idt_B: 1.398 \n",
            "(epoch: 4, iters: 400, time: 1.410, data: 0.002) D_A: 0.073 G_A: 0.759 cycle_A: 3.171 idt_A: 0.408 D_B: 0.293 G_B: 0.148 cycle_B: 0.954 idt_B: 1.357 \n",
            "(epoch: 4, iters: 500, time: 1.931, data: 0.002) D_A: 0.081 G_A: 0.679 cycle_A: 3.100 idt_A: 0.480 D_B: 0.192 G_B: 0.211 cycle_B: 1.224 idt_B: 1.187 \n",
            "End of epoch 4 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 5, iters: 100, time: 1.397, data: 0.565) D_A: 0.026 G_A: 1.098 cycle_A: 3.174 idt_A: 0.467 D_B: 0.074 G_B: 0.740 cycle_B: 1.306 idt_B: 1.634 \n",
            "(epoch: 5, iters: 200, time: 1.403, data: 0.003) D_A: 0.093 G_A: 0.494 cycle_A: 2.177 idt_A: 0.542 D_B: 0.552 G_B: 1.180 cycle_B: 0.960 idt_B: 0.947 \n",
            "(epoch: 5, iters: 300, time: 1.394, data: 0.003) D_A: 0.102 G_A: 0.351 cycle_A: 1.973 idt_A: 0.424 D_B: 0.230 G_B: 0.948 cycle_B: 0.969 idt_B: 0.867 \n",
            "(epoch: 5, iters: 400, time: 5.720, data: 0.002) D_A: 0.041 G_A: 0.730 cycle_A: 2.339 idt_A: 0.396 D_B: 0.024 G_B: 0.295 cycle_B: 0.966 idt_B: 0.832 \n",
            "(epoch: 5, iters: 500, time: 1.409, data: 0.002) D_A: 0.025 G_A: 0.605 cycle_A: 2.695 idt_A: 0.402 D_B: 0.230 G_B: 0.587 cycle_B: 1.200 idt_B: 0.677 \n",
            "saving the model at the end of epoch 5, iters 2500\n",
            "End of epoch 5 / 200 \t Time Taken: 671 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 6, iters: 100, time: 1.417, data: 0.588) D_A: 0.016 G_A: 1.101 cycle_A: 2.837 idt_A: 0.414 D_B: 0.110 G_B: 0.467 cycle_B: 1.197 idt_B: 0.959 \n",
            "(epoch: 6, iters: 200, time: 1.411, data: 0.002) D_A: 0.074 G_A: 0.651 cycle_A: 2.142 idt_A: 0.588 D_B: 0.265 G_B: 0.356 cycle_B: 1.034 idt_B: 0.776 \n",
            "(epoch: 6, iters: 300, time: 5.741, data: 0.002) D_A: 0.048 G_A: 1.277 cycle_A: 2.190 idt_A: 0.407 D_B: 0.089 G_B: 0.346 cycle_B: 0.980 idt_B: 0.693 \n",
            "(epoch: 6, iters: 400, time: 1.400, data: 0.002) D_A: 0.033 G_A: 0.968 cycle_A: 3.159 idt_A: 0.389 D_B: 0.173 G_B: 0.346 cycle_B: 0.989 idt_B: 1.532 \n",
            "(epoch: 6, iters: 500, time: 1.411, data: 0.002) D_A: 0.062 G_A: 0.786 cycle_A: 1.446 idt_A: 0.399 D_B: 0.136 G_B: 0.203 cycle_B: 1.008 idt_B: 0.477 \n",
            "End of epoch 6 / 200 \t Time Taken: 668 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 7, iters: 100, time: 1.421, data: 0.547) D_A: 0.041 G_A: 0.978 cycle_A: 1.476 idt_A: 0.405 D_B: 0.128 G_B: 1.635 cycle_B: 0.955 idt_B: 0.553 \n",
            "(epoch: 7, iters: 200, time: 5.673, data: 0.002) D_A: 0.061 G_A: 0.714 cycle_A: 1.252 idt_A: 0.385 D_B: 0.204 G_B: 0.767 cycle_B: 0.944 idt_B: 0.610 \n",
            "(epoch: 7, iters: 300, time: 1.402, data: 0.003) D_A: 0.016 G_A: 0.810 cycle_A: 1.681 idt_A: 0.381 D_B: 0.080 G_B: 0.257 cycle_B: 0.937 idt_B: 0.736 \n",
            "(epoch: 7, iters: 400, time: 1.416, data: 0.002) D_A: 0.032 G_A: 0.766 cycle_A: 1.872 idt_A: 0.387 D_B: 0.251 G_B: 0.212 cycle_B: 0.919 idt_B: 0.410 \n",
            "(epoch: 7, iters: 500, time: 1.406, data: 0.003) D_A: 0.058 G_A: 0.556 cycle_A: 2.871 idt_A: 0.414 D_B: 0.225 G_B: 0.870 cycle_B: 0.951 idt_B: 0.947 \n",
            "End of epoch 7 / 200 \t Time Taken: 668 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 8, iters: 100, time: 6.192, data: 0.829) D_A: 0.065 G_A: 0.415 cycle_A: 2.534 idt_A: 0.382 D_B: 0.076 G_B: 0.182 cycle_B: 0.933 idt_B: 0.979 \n",
            "(epoch: 8, iters: 200, time: 1.418, data: 0.003) D_A: 0.063 G_A: 0.929 cycle_A: 2.317 idt_A: 0.386 D_B: 0.301 G_B: 0.089 cycle_B: 0.945 idt_B: 0.510 \n",
            "(epoch: 8, iters: 300, time: 1.414, data: 0.003) D_A: 0.045 G_A: 0.464 cycle_A: 1.519 idt_A: 0.381 D_B: 0.129 G_B: 0.530 cycle_B: 0.986 idt_B: 0.643 \n",
            "(epoch: 8, iters: 400, time: 1.411, data: 0.002) D_A: 0.015 G_A: 1.088 cycle_A: 1.806 idt_A: 0.419 D_B: 0.154 G_B: 0.760 cycle_B: 1.018 idt_B: 0.473 \n",
            "(epoch: 8, iters: 500, time: 1.975, data: 0.003) D_A: 0.016 G_A: 0.660 cycle_A: 3.634 idt_A: 0.403 D_B: 0.273 G_B: 0.457 cycle_B: 1.067 idt_B: 1.159 \n",
            "End of epoch 8 / 200 \t Time Taken: 669 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 9, iters: 100, time: 1.406, data: 0.113) D_A: 0.157 G_A: 0.394 cycle_A: 1.937 idt_A: 0.366 D_B: 0.143 G_B: 0.727 cycle_B: 0.964 idt_B: 0.779 \n",
            "(epoch: 9, iters: 200, time: 1.407, data: 0.002) D_A: 0.047 G_A: 0.723 cycle_A: 1.723 idt_A: 0.372 D_B: 0.064 G_B: 0.275 cycle_B: 0.938 idt_B: 0.614 \n",
            "(epoch: 9, iters: 300, time: 1.413, data: 0.002) D_A: 0.091 G_A: 0.449 cycle_A: 2.070 idt_A: 0.367 D_B: 0.333 G_B: 0.432 cycle_B: 0.935 idt_B: 1.152 \n",
            "(epoch: 9, iters: 400, time: 1.911, data: 0.003) D_A: 0.063 G_A: 1.433 cycle_A: 2.159 idt_A: 0.404 D_B: 0.112 G_B: 0.849 cycle_B: 1.062 idt_B: 1.021 \n",
            "(epoch: 9, iters: 500, time: 1.418, data: 0.002) D_A: 0.034 G_A: 0.658 cycle_A: 2.261 idt_A: 0.391 D_B: 0.116 G_B: 0.332 cycle_B: 0.942 idt_B: 0.933 \n",
            "End of epoch 9 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 10, iters: 100, time: 1.407, data: 0.104) D_A: 0.036 G_A: 0.664 cycle_A: 1.142 idt_A: 0.376 D_B: 0.092 G_B: 0.728 cycle_B: 1.088 idt_B: 0.510 \n",
            "(epoch: 10, iters: 200, time: 1.410, data: 0.002) D_A: 0.069 G_A: 0.923 cycle_A: 1.530 idt_A: 0.371 D_B: 0.342 G_B: 0.168 cycle_B: 1.052 idt_B: 0.395 \n",
            "(epoch: 10, iters: 300, time: 1.917, data: 0.002) D_A: 0.030 G_A: 0.900 cycle_A: 2.382 idt_A: 0.381 D_B: 0.157 G_B: 0.421 cycle_B: 0.998 idt_B: 0.709 \n",
            "(epoch: 10, iters: 400, time: 1.410, data: 0.002) D_A: 0.037 G_A: 0.755 cycle_A: 3.196 idt_A: 0.410 D_B: 0.236 G_B: 0.330 cycle_B: 1.161 idt_B: 1.258 \n",
            "(epoch: 10, iters: 500, time: 1.402, data: 0.003) D_A: 0.037 G_A: 0.478 cycle_A: 1.941 idt_A: 0.391 D_B: 0.139 G_B: 0.515 cycle_B: 1.074 idt_B: 0.839 \n",
            "saving the latest model (epoch 10, total_iters 5000)\n",
            "saving the model at the end of epoch 10, iters 5000\n",
            "End of epoch 10 / 200 \t Time Taken: 669 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 11, iters: 100, time: 1.412, data: 0.669) D_A: 0.035 G_A: 0.783 cycle_A: 1.808 idt_A: 0.392 D_B: 0.221 G_B: 0.754 cycle_B: 0.927 idt_B: 0.842 \n",
            "(epoch: 11, iters: 200, time: 2.045, data: 0.002) D_A: 0.043 G_A: 0.778 cycle_A: 1.525 idt_A: 0.366 D_B: 0.231 G_B: 0.077 cycle_B: 0.988 idt_B: 0.499 \n",
            "(epoch: 11, iters: 300, time: 1.411, data: 0.003) D_A: 0.029 G_A: 1.064 cycle_A: 2.928 idt_A: 0.363 D_B: 0.137 G_B: 0.434 cycle_B: 0.984 idt_B: 1.339 \n",
            "(epoch: 11, iters: 400, time: 1.416, data: 0.002) D_A: 0.032 G_A: 0.690 cycle_A: 1.421 idt_A: 0.360 D_B: 0.347 G_B: 0.055 cycle_B: 0.922 idt_B: 0.855 \n",
            "(epoch: 11, iters: 500, time: 1.409, data: 0.003) D_A: 0.036 G_A: 0.755 cycle_A: 1.815 idt_A: 0.358 D_B: 0.107 G_B: 0.313 cycle_B: 0.906 idt_B: 0.766 \n",
            "End of epoch 11 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 12, iters: 100, time: 2.065, data: 0.122) D_A: 0.025 G_A: 1.025 cycle_A: 1.881 idt_A: 0.378 D_B: 0.170 G_B: 0.319 cycle_B: 1.092 idt_B: 0.802 \n",
            "(epoch: 12, iters: 200, time: 1.409, data: 0.003) D_A: 0.011 G_A: 0.425 cycle_A: 1.671 idt_A: 0.375 D_B: 0.149 G_B: 0.326 cycle_B: 0.959 idt_B: 0.762 \n",
            "(epoch: 12, iters: 300, time: 1.412, data: 0.002) D_A: 0.036 G_A: 0.604 cycle_A: 2.585 idt_A: 0.357 D_B: 0.398 G_B: 0.832 cycle_B: 0.971 idt_B: 0.944 \n",
            "(epoch: 12, iters: 400, time: 1.401, data: 0.003) D_A: 0.025 G_A: 1.097 cycle_A: 3.366 idt_A: 0.353 D_B: 0.062 G_B: 0.535 cycle_B: 0.975 idt_B: 1.434 \n",
            "(epoch: 12, iters: 500, time: 2.030, data: 0.002) D_A: 0.017 G_A: 0.940 cycle_A: 1.300 idt_A: 0.361 D_B: 0.138 G_B: 0.318 cycle_B: 0.951 idt_B: 0.495 \n",
            "End of epoch 12 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 13, iters: 100, time: 1.408, data: 0.159) D_A: 0.040 G_A: 0.785 cycle_A: 1.819 idt_A: 0.375 D_B: 0.107 G_B: 0.547 cycle_B: 0.938 idt_B: 0.747 \n",
            "(epoch: 13, iters: 200, time: 1.408, data: 0.002) D_A: 0.106 G_A: 1.304 cycle_A: 1.044 idt_A: 0.356 D_B: 0.211 G_B: 0.478 cycle_B: 0.896 idt_B: 0.437 \n",
            "(epoch: 13, iters: 300, time: 1.415, data: 0.002) D_A: 0.021 G_A: 0.853 cycle_A: 2.571 idt_A: 0.359 D_B: 0.145 G_B: 0.557 cycle_B: 0.969 idt_B: 0.834 \n",
            "(epoch: 13, iters: 400, time: 1.954, data: 0.003) D_A: 0.032 G_A: 1.213 cycle_A: 2.422 idt_A: 0.413 D_B: 0.147 G_B: 0.414 cycle_B: 1.012 idt_B: 0.671 \n",
            "(epoch: 13, iters: 500, time: 1.409, data: 0.002) D_A: 0.035 G_A: 0.574 cycle_A: 1.972 idt_A: 0.349 D_B: 0.085 G_B: 0.312 cycle_B: 0.949 idt_B: 0.697 \n",
            "End of epoch 13 / 200 \t Time Taken: 662 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 14, iters: 100, time: 1.405, data: 0.792) D_A: 0.050 G_A: 1.080 cycle_A: 2.558 idt_A: 0.372 D_B: 0.058 G_B: 0.666 cycle_B: 0.943 idt_B: 1.010 \n",
            "(epoch: 14, iters: 200, time: 1.397, data: 0.002) D_A: 0.036 G_A: 1.090 cycle_A: 5.351 idt_A: 0.350 D_B: 0.226 G_B: 0.181 cycle_B: 1.078 idt_B: 2.210 \n",
            "(epoch: 14, iters: 300, time: 1.934, data: 0.002) D_A: 0.031 G_A: 0.970 cycle_A: 2.409 idt_A: 0.346 D_B: 0.201 G_B: 0.446 cycle_B: 0.939 idt_B: 1.064 \n",
            "(epoch: 14, iters: 400, time: 1.409, data: 0.002) D_A: 0.030 G_A: 0.694 cycle_A: 1.599 idt_A: 0.351 D_B: 0.276 G_B: 0.584 cycle_B: 0.917 idt_B: 0.606 \n",
            "(epoch: 14, iters: 500, time: 1.406, data: 0.002) D_A: 0.046 G_A: 1.131 cycle_A: 2.583 idt_A: 0.543 D_B: 0.289 G_B: 0.107 cycle_B: 1.024 idt_B: 0.811 \n",
            "End of epoch 14 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 15, iters: 100, time: 1.406, data: 0.140) D_A: 0.044 G_A: 0.608 cycle_A: 2.123 idt_A: 0.359 D_B: 0.038 G_B: 0.977 cycle_B: 0.960 idt_B: 0.814 \n",
            "(epoch: 15, iters: 200, time: 2.078, data: 0.002) D_A: 0.054 G_A: 0.777 cycle_A: 1.708 idt_A: 0.341 D_B: 0.311 G_B: 0.536 cycle_B: 0.931 idt_B: 0.666 \n",
            "(epoch: 15, iters: 300, time: 1.407, data: 0.003) D_A: 0.011 G_A: 1.086 cycle_A: 1.667 idt_A: 0.336 D_B: 0.145 G_B: 0.492 cycle_B: 0.888 idt_B: 0.924 \n",
            "(epoch: 15, iters: 400, time: 1.408, data: 0.002) D_A: 0.027 G_A: 0.924 cycle_A: 1.652 idt_A: 0.340 D_B: 0.284 G_B: 0.634 cycle_B: 0.932 idt_B: 0.709 \n",
            "(epoch: 15, iters: 500, time: 1.405, data: 0.002) D_A: 0.035 G_A: 1.411 cycle_A: 1.455 idt_A: 0.346 D_B: 0.027 G_B: 0.457 cycle_B: 1.000 idt_B: 0.641 \n",
            "saving the model at the end of epoch 15, iters 7500\n",
            "End of epoch 15 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 16, iters: 100, time: 2.118, data: 0.120) D_A: 0.028 G_A: 0.856 cycle_A: 2.521 idt_A: 0.356 D_B: 0.173 G_B: 0.318 cycle_B: 0.975 idt_B: 0.768 \n",
            "(epoch: 16, iters: 200, time: 1.412, data: 0.003) D_A: 0.077 G_A: 1.307 cycle_A: 1.704 idt_A: 0.339 D_B: 0.225 G_B: 0.258 cycle_B: 0.905 idt_B: 0.699 \n",
            "(epoch: 16, iters: 300, time: 1.412, data: 0.002) D_A: 0.031 G_A: 0.709 cycle_A: 1.674 idt_A: 0.345 D_B: 0.165 G_B: 0.327 cycle_B: 0.992 idt_B: 0.664 \n",
            "(epoch: 16, iters: 400, time: 1.411, data: 0.003) D_A: 0.025 G_A: 0.902 cycle_A: 1.725 idt_A: 0.356 D_B: 0.259 G_B: 0.122 cycle_B: 0.931 idt_B: 0.661 \n",
            "(epoch: 16, iters: 500, time: 1.957, data: 0.002) D_A: 0.068 G_A: 0.599 cycle_A: 1.041 idt_A: 0.365 D_B: 0.039 G_B: 0.284 cycle_B: 0.939 idt_B: 0.523 \n",
            "End of epoch 16 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 17, iters: 100, time: 1.409, data: 0.116) D_A: 0.027 G_A: 1.025 cycle_A: 2.994 idt_A: 0.343 D_B: 0.152 G_B: 0.333 cycle_B: 0.884 idt_B: 1.518 \n",
            "(epoch: 17, iters: 200, time: 1.408, data: 0.002) D_A: 0.096 G_A: 0.406 cycle_A: 1.958 idt_A: 0.330 D_B: 0.081 G_B: 0.460 cycle_B: 0.888 idt_B: 0.895 \n",
            "(epoch: 17, iters: 300, time: 1.417, data: 0.002) D_A: 0.014 G_A: 0.702 cycle_A: 1.848 idt_A: 0.337 D_B: 0.277 G_B: 0.235 cycle_B: 0.942 idt_B: 0.768 \n",
            "(epoch: 17, iters: 400, time: 1.968, data: 0.002) D_A: 0.264 G_A: 0.281 cycle_A: 1.148 idt_A: 0.349 D_B: 0.143 G_B: 0.439 cycle_B: 0.916 idt_B: 0.430 \n",
            "(epoch: 17, iters: 500, time: 1.407, data: 0.002) D_A: 0.210 G_A: 0.317 cycle_A: 1.702 idt_A: 0.355 D_B: 0.179 G_B: 0.803 cycle_B: 0.877 idt_B: 0.652 \n",
            "End of epoch 17 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 18, iters: 100, time: 1.406, data: 0.128) D_A: 0.260 G_A: 0.216 cycle_A: 1.544 idt_A: 0.344 D_B: 0.225 G_B: 0.200 cycle_B: 0.957 idt_B: 0.518 \n",
            "(epoch: 18, iters: 200, time: 1.409, data: 0.002) D_A: 0.235 G_A: 0.285 cycle_A: 2.873 idt_A: 0.334 D_B: 0.225 G_B: 0.254 cycle_B: 0.945 idt_B: 0.893 \n",
            "(epoch: 18, iters: 300, time: 2.069, data: 0.002) D_A: 0.222 G_A: 0.305 cycle_A: 2.019 idt_A: 0.324 D_B: 0.059 G_B: 0.892 cycle_B: 0.786 idt_B: 1.392 \n",
            "(epoch: 18, iters: 400, time: 1.411, data: 0.002) D_A: 0.223 G_A: 0.280 cycle_A: 1.765 idt_A: 0.323 D_B: 0.149 G_B: 0.498 cycle_B: 0.922 idt_B: 0.727 \n",
            "(epoch: 18, iters: 500, time: 1.415, data: 0.002) D_A: 0.188 G_A: 0.345 cycle_A: 1.270 idt_A: 0.329 D_B: 0.127 G_B: 0.337 cycle_B: 0.920 idt_B: 0.507 \n",
            "End of epoch 18 / 200 \t Time Taken: 663 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 19, iters: 100, time: 1.406, data: 0.587) D_A: 0.227 G_A: 0.387 cycle_A: 1.030 idt_A: 0.338 D_B: 0.274 G_B: 0.191 cycle_B: 0.945 idt_B: 0.509 \n",
            "(epoch: 19, iters: 200, time: 2.173, data: 0.002) D_A: 0.251 G_A: 0.456 cycle_A: 1.098 idt_A: 0.331 D_B: 0.288 G_B: 0.613 cycle_B: 0.890 idt_B: 0.551 \n",
            "(epoch: 19, iters: 300, time: 1.415, data: 0.002) D_A: 0.175 G_A: 0.411 cycle_A: 1.244 idt_A: 0.330 D_B: 0.148 G_B: 0.447 cycle_B: 0.897 idt_B: 0.603 \n",
            "(epoch: 19, iters: 400, time: 1.412, data: 0.002) D_A: 0.198 G_A: 0.401 cycle_A: 1.185 idt_A: 0.328 D_B: 0.117 G_B: 0.329 cycle_B: 0.878 idt_B: 0.628 \n",
            "(epoch: 19, iters: 500, time: 1.413, data: 0.002) D_A: 0.188 G_A: 0.290 cycle_A: 1.523 idt_A: 0.328 D_B: 0.108 G_B: 0.570 cycle_B: 0.914 idt_B: 0.568 \n",
            "End of epoch 19 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 20, iters: 100, time: 2.048, data: 0.136) D_A: 0.175 G_A: 0.398 cycle_A: 1.487 idt_A: 0.363 D_B: 0.278 G_B: 0.500 cycle_B: 0.987 idt_B: 0.616 \n",
            "(epoch: 20, iters: 200, time: 1.409, data: 0.002) D_A: 0.243 G_A: 0.190 cycle_A: 1.643 idt_A: 0.329 D_B: 0.108 G_B: 0.871 cycle_B: 0.875 idt_B: 0.701 \n",
            "(epoch: 20, iters: 300, time: 1.419, data: 0.002) D_A: 0.429 G_A: 1.146 cycle_A: 2.449 idt_A: 0.341 D_B: 0.071 G_B: 0.523 cycle_B: 0.951 idt_B: 0.929 \n",
            "(epoch: 20, iters: 400, time: 1.412, data: 0.003) D_A: 0.213 G_A: 0.205 cycle_A: 1.953 idt_A: 0.322 D_B: 0.329 G_B: 0.840 cycle_B: 0.850 idt_B: 0.571 \n",
            "(epoch: 20, iters: 500, time: 1.977, data: 0.002) D_A: 0.102 G_A: 0.596 cycle_A: 2.208 idt_A: 0.339 D_B: 0.217 G_B: 0.260 cycle_B: 0.929 idt_B: 0.926 \n",
            "saving the latest model (epoch 20, total_iters 10000)\n",
            "saving the model at the end of epoch 20, iters 10000\n",
            "End of epoch 20 / 200 \t Time Taken: 668 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 21, iters: 100, time: 1.409, data: 0.161) D_A: 0.128 G_A: 0.548 cycle_A: 1.319 idt_A: 0.335 D_B: 0.144 G_B: 0.318 cycle_B: 0.979 idt_B: 0.517 \n",
            "(epoch: 21, iters: 200, time: 1.412, data: 0.002) D_A: 0.116 G_A: 0.342 cycle_A: 1.287 idt_A: 0.327 D_B: 0.090 G_B: 0.112 cycle_B: 0.903 idt_B: 0.599 \n",
            "(epoch: 21, iters: 300, time: 1.417, data: 0.002) D_A: 0.123 G_A: 0.407 cycle_A: 2.851 idt_A: 0.332 D_B: 0.285 G_B: 0.479 cycle_B: 0.924 idt_B: 1.223 \n",
            "(epoch: 21, iters: 400, time: 2.142, data: 0.003) D_A: 0.120 G_A: 0.560 cycle_A: 1.170 idt_A: 0.329 D_B: 0.093 G_B: 0.583 cycle_B: 0.969 idt_B: 0.574 \n",
            "(epoch: 21, iters: 500, time: 1.415, data: 0.002) D_A: 0.088 G_A: 0.357 cycle_A: 1.890 idt_A: 0.333 D_B: 0.157 G_B: 0.325 cycle_B: 0.909 idt_B: 0.704 \n",
            "End of epoch 21 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 22, iters: 100, time: 1.413, data: 0.592) D_A: 0.211 G_A: 0.756 cycle_A: 1.301 idt_A: 0.344 D_B: 0.166 G_B: 0.289 cycle_B: 0.966 idt_B: 0.395 \n",
            "(epoch: 22, iters: 200, time: 1.411, data: 0.002) D_A: 0.253 G_A: 1.197 cycle_A: 1.465 idt_A: 0.327 D_B: 0.260 G_B: 0.241 cycle_B: 0.881 idt_B: 0.473 \n",
            "(epoch: 22, iters: 300, time: 2.144, data: 0.003) D_A: 0.140 G_A: 0.514 cycle_A: 1.929 idt_A: 0.319 D_B: 0.270 G_B: 0.445 cycle_B: 0.906 idt_B: 0.504 \n",
            "(epoch: 22, iters: 400, time: 1.416, data: 0.002) D_A: 0.103 G_A: 0.542 cycle_A: 1.047 idt_A: 0.329 D_B: 0.206 G_B: 0.732 cycle_B: 0.912 idt_B: 0.439 \n",
            "(epoch: 22, iters: 500, time: 1.406, data: 0.002) D_A: 0.044 G_A: 0.703 cycle_A: 2.144 idt_A: 0.332 D_B: 0.071 G_B: 0.323 cycle_B: 1.190 idt_B: 0.447 \n",
            "End of epoch 22 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 23, iters: 100, time: 1.410, data: 0.104) D_A: 0.043 G_A: 0.712 cycle_A: 1.585 idt_A: 0.362 D_B: 0.155 G_B: 0.642 cycle_B: 1.055 idt_B: 0.542 \n",
            "(epoch: 23, iters: 200, time: 1.990, data: 0.002) D_A: 0.124 G_A: 0.437 cycle_A: 2.131 idt_A: 0.340 D_B: 0.241 G_B: 0.171 cycle_B: 0.986 idt_B: 0.957 \n",
            "(epoch: 23, iters: 300, time: 1.411, data: 0.002) D_A: 0.100 G_A: 0.500 cycle_A: 1.919 idt_A: 0.335 D_B: 0.158 G_B: 0.306 cycle_B: 1.004 idt_B: 0.623 \n",
            "(epoch: 23, iters: 400, time: 1.414, data: 0.002) D_A: 0.048 G_A: 0.756 cycle_A: 2.601 idt_A: 0.338 D_B: 0.304 G_B: 0.076 cycle_B: 0.921 idt_B: 1.175 \n",
            "(epoch: 23, iters: 500, time: 1.418, data: 0.002) D_A: 0.077 G_A: 0.563 cycle_A: 2.195 idt_A: 0.353 D_B: 0.239 G_B: 0.517 cycle_B: 1.007 idt_B: 0.756 \n",
            "End of epoch 23 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 24, iters: 100, time: 1.999, data: 0.150) D_A: 0.049 G_A: 0.626 cycle_A: 4.187 idt_A: 0.341 D_B: 0.173 G_B: 0.173 cycle_B: 0.991 idt_B: 1.965 \n",
            "(epoch: 24, iters: 200, time: 1.422, data: 0.003) D_A: 0.065 G_A: 1.260 cycle_A: 1.437 idt_A: 0.411 D_B: 0.075 G_B: 0.675 cycle_B: 0.942 idt_B: 0.552 \n",
            "(epoch: 24, iters: 300, time: 1.415, data: 0.002) D_A: 0.081 G_A: 0.556 cycle_A: 1.466 idt_A: 0.349 D_B: 0.034 G_B: 0.438 cycle_B: 0.868 idt_B: 0.499 \n",
            "(epoch: 24, iters: 400, time: 1.414, data: 0.003) D_A: 0.039 G_A: 0.311 cycle_A: 1.457 idt_A: 0.333 D_B: 0.086 G_B: 0.239 cycle_B: 1.030 idt_B: 0.640 \n",
            "(epoch: 24, iters: 500, time: 2.031, data: 0.002) D_A: 0.048 G_A: 0.937 cycle_A: 1.437 idt_A: 0.373 D_B: 0.055 G_B: 0.835 cycle_B: 0.997 idt_B: 0.497 \n",
            "End of epoch 24 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 25, iters: 100, time: 1.414, data: 0.173) D_A: 0.073 G_A: 0.504 cycle_A: 2.558 idt_A: 0.340 D_B: 0.024 G_B: 0.757 cycle_B: 0.912 idt_B: 1.082 \n",
            "(epoch: 25, iters: 200, time: 1.407, data: 0.002) D_A: 0.062 G_A: 0.800 cycle_A: 3.257 idt_A: 0.331 D_B: 0.172 G_B: 0.245 cycle_B: 1.040 idt_B: 1.116 \n",
            "(epoch: 25, iters: 300, time: 1.411, data: 0.002) D_A: 0.039 G_A: 0.730 cycle_A: 2.256 idt_A: 0.372 D_B: 0.165 G_B: 0.356 cycle_B: 1.030 idt_B: 0.759 \n",
            "(epoch: 25, iters: 400, time: 2.163, data: 0.002) D_A: 0.030 G_A: 1.033 cycle_A: 1.436 idt_A: 0.335 D_B: 0.149 G_B: 0.280 cycle_B: 0.870 idt_B: 0.602 \n",
            "(epoch: 25, iters: 500, time: 1.415, data: 0.002) D_A: 0.064 G_A: 0.802 cycle_A: 1.440 idt_A: 0.338 D_B: 0.258 G_B: 0.158 cycle_B: 0.927 idt_B: 0.457 \n",
            "saving the model at the end of epoch 25, iters 12500\n",
            "End of epoch 25 / 200 \t Time Taken: 666 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 26, iters: 100, time: 1.407, data: 0.584) D_A: 0.071 G_A: 1.141 cycle_A: 1.667 idt_A: 0.322 D_B: 0.193 G_B: 0.517 cycle_B: 0.888 idt_B: 0.598 \n",
            "(epoch: 26, iters: 200, time: 1.409, data: 0.002) D_A: 0.073 G_A: 0.800 cycle_A: 1.376 idt_A: 0.319 D_B: 0.085 G_B: 0.564 cycle_B: 1.024 idt_B: 0.576 \n",
            "(epoch: 26, iters: 300, time: 2.027, data: 0.003) D_A: 0.026 G_A: 0.887 cycle_A: 1.718 idt_A: 0.335 D_B: 0.211 G_B: 0.380 cycle_B: 0.949 idt_B: 0.746 \n",
            "(epoch: 26, iters: 400, time: 1.404, data: 0.002) D_A: 0.028 G_A: 0.761 cycle_A: 2.565 idt_A: 0.335 D_B: 0.242 G_B: 0.524 cycle_B: 0.902 idt_B: 0.930 \n",
            "(epoch: 26, iters: 500, time: 1.401, data: 0.002) D_A: 0.042 G_A: 1.115 cycle_A: 7.954 idt_A: 0.324 D_B: 0.061 G_B: 0.411 cycle_B: 0.933 idt_B: 4.091 \n",
            "End of epoch 26 / 200 \t Time Taken: 665 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 27, iters: 100, time: 1.405, data: 0.135) D_A: 0.053 G_A: 0.784 cycle_A: 1.226 idt_A: 0.325 D_B: 0.303 G_B: 0.285 cycle_B: 0.949 idt_B: 0.415 \n",
            "(epoch: 27, iters: 200, time: 2.032, data: 0.002) D_A: 0.025 G_A: 0.841 cycle_A: 1.988 idt_A: 0.321 D_B: 0.192 G_B: 0.172 cycle_B: 0.948 idt_B: 0.759 \n",
            "(epoch: 27, iters: 300, time: 1.410, data: 0.002) D_A: 0.037 G_A: 1.054 cycle_A: 2.472 idt_A: 0.317 D_B: 0.138 G_B: 0.413 cycle_B: 0.908 idt_B: 1.138 \n",
            "(epoch: 27, iters: 400, time: 1.400, data: 0.002) D_A: 0.091 G_A: 0.590 cycle_A: 1.609 idt_A: 0.322 D_B: 0.062 G_B: 0.323 cycle_B: 0.909 idt_B: 0.605 \n",
            "(epoch: 27, iters: 500, time: 1.406, data: 0.002) D_A: 0.040 G_A: 0.847 cycle_A: 1.146 idt_A: 0.328 D_B: 0.055 G_B: 0.561 cycle_B: 0.897 idt_B: 0.487 \n",
            "End of epoch 27 / 200 \t Time Taken: 661 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 28, iters: 100, time: 2.037, data: 0.147) D_A: 0.077 G_A: 0.943 cycle_A: 0.953 idt_A: 0.319 D_B: 0.089 G_B: 0.248 cycle_B: 0.856 idt_B: 0.344 \n",
            "(epoch: 28, iters: 200, time: 1.402, data: 0.002) D_A: 0.135 G_A: 0.868 cycle_A: 1.140 idt_A: 0.324 D_B: 0.198 G_B: 0.481 cycle_B: 0.878 idt_B: 0.457 \n",
            "(epoch: 28, iters: 300, time: 1.405, data: 0.002) D_A: 0.051 G_A: 0.478 cycle_A: 1.623 idt_A: 0.311 D_B: 0.151 G_B: 0.125 cycle_B: 0.867 idt_B: 0.696 \n",
            "(epoch: 28, iters: 400, time: 1.400, data: 0.002) D_A: 0.089 G_A: 1.151 cycle_A: 2.163 idt_A: 0.323 D_B: 0.075 G_B: 0.456 cycle_B: 0.928 idt_B: 0.916 \n",
            "(epoch: 28, iters: 500, time: 2.039, data: 0.002) D_A: 0.222 G_A: 0.502 cycle_A: 1.942 idt_A: 0.311 D_B: 0.187 G_B: 0.368 cycle_B: 0.853 idt_B: 0.628 \n",
            "End of epoch 28 / 200 \t Time Taken: 661 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 29, iters: 100, time: 1.405, data: 0.117) D_A: 0.061 G_A: 1.204 cycle_A: 0.949 idt_A: 0.327 D_B: 0.230 G_B: 0.355 cycle_B: 0.957 idt_B: 0.491 \n",
            "(epoch: 29, iters: 200, time: 1.403, data: 0.002) D_A: 0.046 G_A: 0.441 cycle_A: 1.597 idt_A: 0.315 D_B: 0.109 G_B: 0.394 cycle_B: 0.894 idt_B: 0.482 \n",
            "(epoch: 29, iters: 300, time: 1.396, data: 0.002) D_A: 0.063 G_A: 0.907 cycle_A: 1.668 idt_A: 0.319 D_B: 0.154 G_B: 0.232 cycle_B: 0.884 idt_B: 0.544 \n",
            "(epoch: 29, iters: 400, time: 2.198, data: 0.002) D_A: 0.064 G_A: 0.739 cycle_A: 1.879 idt_A: 0.324 D_B: 0.106 G_B: 0.826 cycle_B: 0.901 idt_B: 0.576 \n",
            "(epoch: 29, iters: 500, time: 1.405, data: 0.002) D_A: 0.017 G_A: 0.852 cycle_A: 1.712 idt_A: 0.414 D_B: 0.061 G_B: 0.562 cycle_B: 1.006 idt_B: 0.552 \n",
            "End of epoch 29 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 30, iters: 100, time: 1.402, data: 0.153) D_A: 0.046 G_A: 1.295 cycle_A: 2.778 idt_A: 0.342 D_B: 0.074 G_B: 0.684 cycle_B: 1.033 idt_B: 1.471 \n",
            "(epoch: 30, iters: 200, time: 1.397, data: 0.002) D_A: 0.064 G_A: 0.988 cycle_A: 1.504 idt_A: 0.322 D_B: 0.161 G_B: 0.109 cycle_B: 0.995 idt_B: 0.584 \n",
            "(epoch: 30, iters: 300, time: 2.016, data: 0.003) D_A: 0.037 G_A: 0.875 cycle_A: 2.062 idt_A: 0.334 D_B: 0.263 G_B: 0.560 cycle_B: 0.983 idt_B: 0.833 \n",
            "(epoch: 30, iters: 400, time: 1.397, data: 0.002) D_A: 0.092 G_A: 0.565 cycle_A: 0.714 idt_A: 0.323 D_B: 0.383 G_B: 0.086 cycle_B: 0.915 idt_B: 0.473 \n",
            "(epoch: 30, iters: 500, time: 1.402, data: 0.002) D_A: 0.032 G_A: 0.855 cycle_A: 0.919 idt_A: 0.307 D_B: 0.171 G_B: 0.612 cycle_B: 0.873 idt_B: 0.447 \n",
            "saving the latest model (epoch 30, total_iters 15000)\n",
            "saving the model at the end of epoch 30, iters 15000\n",
            "End of epoch 30 / 200 \t Time Taken: 667 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 31, iters: 100, time: 1.404, data: 0.101) D_A: 0.035 G_A: 0.753 cycle_A: 2.179 idt_A: 0.322 D_B: 0.236 G_B: 0.884 cycle_B: 1.023 idt_B: 1.043 \n",
            "(epoch: 31, iters: 200, time: 2.096, data: 0.002) D_A: 0.028 G_A: 1.047 cycle_A: 1.744 idt_A: 0.333 D_B: 0.136 G_B: 0.187 cycle_B: 0.999 idt_B: 0.676 \n",
            "(epoch: 31, iters: 300, time: 1.400, data: 0.002) D_A: 0.070 G_A: 0.583 cycle_A: 1.966 idt_A: 0.339 D_B: 0.108 G_B: 0.408 cycle_B: 0.916 idt_B: 0.617 \n",
            "(epoch: 31, iters: 400, time: 1.405, data: 0.002) D_A: 0.109 G_A: 1.072 cycle_A: 1.175 idt_A: 0.314 D_B: 0.186 G_B: 0.281 cycle_B: 0.912 idt_B: 0.510 \n",
            "(epoch: 31, iters: 500, time: 1.402, data: 0.002) D_A: 0.040 G_A: 0.612 cycle_A: 1.143 idt_A: 0.308 D_B: 0.103 G_B: 0.403 cycle_B: 0.889 idt_B: 0.431 \n",
            "End of epoch 31 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 32, iters: 100, time: 2.057, data: 0.121) D_A: 0.023 G_A: 0.961 cycle_A: 1.474 idt_A: 0.317 D_B: 0.140 G_B: 0.490 cycle_B: 0.921 idt_B: 0.604 \n",
            "(epoch: 32, iters: 200, time: 1.407, data: 0.002) D_A: 0.035 G_A: 1.014 cycle_A: 1.944 idt_A: 0.316 D_B: 0.066 G_B: 0.487 cycle_B: 0.897 idt_B: 0.734 \n",
            "(epoch: 32, iters: 300, time: 1.400, data: 0.002) D_A: 0.209 G_A: 0.269 cycle_A: 0.962 idt_A: 0.311 D_B: 0.247 G_B: 0.254 cycle_B: 0.940 idt_B: 0.387 \n",
            "(epoch: 32, iters: 400, time: 1.395, data: 0.002) D_A: 0.250 G_A: 0.187 cycle_A: 1.537 idt_A: 0.308 D_B: 0.166 G_B: 0.126 cycle_B: 0.870 idt_B: 0.602 \n",
            "(epoch: 32, iters: 500, time: 2.159, data: 0.002) D_A: 0.209 G_A: 0.277 cycle_A: 4.910 idt_A: 0.298 D_B: 0.190 G_B: 0.322 cycle_B: 0.863 idt_B: 2.364 \n",
            "End of epoch 32 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 33, iters: 100, time: 1.399, data: 0.831) D_A: 0.149 G_A: 0.398 cycle_A: 1.877 idt_A: 0.295 D_B: 0.053 G_B: 0.555 cycle_B: 0.862 idt_B: 0.878 \n",
            "(epoch: 33, iters: 200, time: 1.406, data: 0.002) D_A: 0.197 G_A: 0.478 cycle_A: 1.475 idt_A: 0.303 D_B: 0.249 G_B: 0.668 cycle_B: 0.889 idt_B: 0.721 \n",
            "(epoch: 33, iters: 300, time: 1.405, data: 0.002) D_A: 0.156 G_A: 0.410 cycle_A: 1.002 idt_A: 0.297 D_B: 0.081 G_B: 0.234 cycle_B: 0.909 idt_B: 0.358 \n",
            "(epoch: 33, iters: 400, time: 2.110, data: 0.002) D_A: 0.076 G_A: 0.422 cycle_A: 1.281 idt_A: 0.299 D_B: 0.304 G_B: 0.399 cycle_B: 0.859 idt_B: 0.417 \n",
            "(epoch: 33, iters: 500, time: 1.408, data: 0.002) D_A: 0.173 G_A: 0.701 cycle_A: 1.397 idt_A: 0.296 D_B: 0.623 G_B: 0.057 cycle_B: 0.937 idt_B: 0.437 \n",
            "End of epoch 33 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 34, iters: 100, time: 1.392, data: 0.555) D_A: 0.215 G_A: 0.799 cycle_A: 3.024 idt_A: 0.299 D_B: 0.135 G_B: 0.416 cycle_B: 0.872 idt_B: 1.064 \n",
            "(epoch: 34, iters: 200, time: 1.408, data: 0.002) D_A: 0.182 G_A: 0.276 cycle_A: 1.468 idt_A: 0.297 D_B: 0.217 G_B: 0.419 cycle_B: 0.858 idt_B: 0.467 \n",
            "(epoch: 34, iters: 300, time: 2.123, data: 0.002) D_A: 0.138 G_A: 0.357 cycle_A: 1.772 idt_A: 0.315 D_B: 0.261 G_B: 0.126 cycle_B: 0.948 idt_B: 0.644 \n",
            "(epoch: 34, iters: 400, time: 1.415, data: 0.002) D_A: 0.103 G_A: 1.035 cycle_A: 2.316 idt_A: 0.292 D_B: 0.037 G_B: 0.178 cycle_B: 0.856 idt_B: 0.842 \n",
            "(epoch: 34, iters: 500, time: 1.410, data: 0.002) D_A: 0.040 G_A: 0.723 cycle_A: 1.807 idt_A: 0.310 D_B: 0.049 G_B: 0.469 cycle_B: 0.877 idt_B: 1.340 \n",
            "End of epoch 34 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 35, iters: 100, time: 1.403, data: 0.858) D_A: 0.057 G_A: 0.516 cycle_A: 1.124 idt_A: 0.302 D_B: 0.169 G_B: 0.465 cycle_B: 0.935 idt_B: 0.726 \n",
            "(epoch: 35, iters: 200, time: 2.092, data: 0.002) D_A: 0.057 G_A: 0.823 cycle_A: 1.639 idt_A: 0.328 D_B: 0.287 G_B: 0.082 cycle_B: 0.981 idt_B: 0.728 \n",
            "(epoch: 35, iters: 300, time: 1.412, data: 0.002) D_A: 0.062 G_A: 0.648 cycle_A: 1.393 idt_A: 0.298 D_B: 0.295 G_B: 0.251 cycle_B: 0.901 idt_B: 0.413 \n",
            "(epoch: 35, iters: 400, time: 1.410, data: 0.002) D_A: 0.065 G_A: 0.969 cycle_A: 4.277 idt_A: 0.304 D_B: 0.041 G_B: 0.444 cycle_B: 0.944 idt_B: 1.575 \n",
            "(epoch: 35, iters: 500, time: 1.405, data: 0.002) D_A: 0.040 G_A: 1.263 cycle_A: 2.625 idt_A: 0.299 D_B: 0.082 G_B: 0.733 cycle_B: 0.890 idt_B: 0.838 \n",
            "saving the model at the end of epoch 35, iters 17500\n",
            "End of epoch 35 / 200 \t Time Taken: 662 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 36, iters: 100, time: 2.090, data: 0.156) D_A: 0.052 G_A: 0.660 cycle_A: 1.502 idt_A: 0.295 D_B: 0.069 G_B: 0.319 cycle_B: 1.011 idt_B: 0.548 \n",
            "(epoch: 36, iters: 200, time: 1.406, data: 0.002) D_A: 0.116 G_A: 0.610 cycle_A: 2.634 idt_A: 0.299 D_B: 0.490 G_B: 0.472 cycle_B: 0.885 idt_B: 0.961 \n",
            "(epoch: 36, iters: 300, time: 1.397, data: 0.002) D_A: 0.052 G_A: 1.046 cycle_A: 1.064 idt_A: 0.294 D_B: 0.082 G_B: 0.388 cycle_B: 0.904 idt_B: 0.543 \n",
            "(epoch: 36, iters: 400, time: 1.408, data: 0.002) D_A: 0.023 G_A: 0.850 cycle_A: 1.532 idt_A: 0.522 D_B: 0.244 G_B: 0.147 cycle_B: 0.876 idt_B: 0.547 \n",
            "(epoch: 36, iters: 500, time: 2.064, data: 0.002) D_A: 0.087 G_A: 0.894 cycle_A: 1.297 idt_A: 0.311 D_B: 0.101 G_B: 0.373 cycle_B: 0.876 idt_B: 0.620 \n",
            "End of epoch 36 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 37, iters: 100, time: 1.398, data: 0.154) D_A: 0.096 G_A: 0.754 cycle_A: 1.477 idt_A: 0.301 D_B: 0.080 G_B: 0.484 cycle_B: 0.871 idt_B: 0.636 \n",
            "(epoch: 37, iters: 200, time: 1.403, data: 0.002) D_A: 0.082 G_A: 0.420 cycle_A: 1.297 idt_A: 0.343 D_B: 0.419 G_B: 1.474 cycle_B: 1.004 idt_B: 0.507 \n",
            "(epoch: 37, iters: 300, time: 1.407, data: 0.002) D_A: 0.031 G_A: 0.719 cycle_A: 1.913 idt_A: 0.301 D_B: 0.119 G_B: 0.271 cycle_B: 0.922 idt_B: 0.784 \n",
            "(epoch: 37, iters: 400, time: 2.116, data: 0.002) D_A: 0.028 G_A: 0.887 cycle_A: 1.543 idt_A: 0.309 D_B: 0.181 G_B: 1.120 cycle_B: 0.915 idt_B: 0.551 \n",
            "(epoch: 37, iters: 500, time: 1.392, data: 0.002) D_A: 0.024 G_A: 1.150 cycle_A: 1.351 idt_A: 0.300 D_B: 0.156 G_B: 0.391 cycle_B: 0.923 idt_B: 0.513 \n",
            "End of epoch 37 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 38, iters: 100, time: 1.400, data: 0.138) D_A: 0.035 G_A: 0.696 cycle_A: 1.256 idt_A: 0.292 D_B: 0.082 G_B: 0.252 cycle_B: 0.872 idt_B: 0.569 \n",
            "(epoch: 38, iters: 200, time: 1.407, data: 0.002) D_A: 0.023 G_A: 0.600 cycle_A: 0.910 idt_A: 0.288 D_B: 0.108 G_B: 0.361 cycle_B: 0.815 idt_B: 0.335 \n",
            "(epoch: 38, iters: 300, time: 2.071, data: 0.002) D_A: 0.032 G_A: 0.736 cycle_A: 1.710 idt_A: 0.292 D_B: 0.172 G_B: 0.423 cycle_B: 0.847 idt_B: 0.556 \n",
            "(epoch: 38, iters: 400, time: 1.413, data: 0.002) D_A: 0.075 G_A: 1.034 cycle_A: 1.781 idt_A: 0.289 D_B: 0.167 G_B: 0.330 cycle_B: 0.852 idt_B: 0.947 \n",
            "(epoch: 38, iters: 500, time: 1.409, data: 0.002) D_A: 0.028 G_A: 0.986 cycle_A: 2.909 idt_A: 0.295 D_B: 0.269 G_B: 0.484 cycle_B: 0.872 idt_B: 1.235 \n",
            "End of epoch 38 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 39, iters: 100, time: 1.397, data: 0.124) D_A: 0.069 G_A: 1.012 cycle_A: 1.962 idt_A: 0.293 D_B: 0.217 G_B: 0.451 cycle_B: 0.845 idt_B: 0.753 \n",
            "(epoch: 39, iters: 200, time: 2.090, data: 0.002) D_A: 0.013 G_A: 1.064 cycle_A: 1.910 idt_A: 0.293 D_B: 0.112 G_B: 0.155 cycle_B: 0.921 idt_B: 0.655 \n",
            "(epoch: 39, iters: 300, time: 1.398, data: 0.002) D_A: 0.024 G_A: 0.573 cycle_A: 1.752 idt_A: 0.291 D_B: 0.126 G_B: 0.724 cycle_B: 0.866 idt_B: 0.688 \n",
            "(epoch: 39, iters: 400, time: 1.407, data: 0.002) D_A: 0.018 G_A: 1.128 cycle_A: 4.047 idt_A: 0.284 D_B: 0.188 G_B: 0.532 cycle_B: 0.891 idt_B: 2.151 \n",
            "(epoch: 39, iters: 500, time: 1.402, data: 0.002) D_A: 0.267 G_A: 0.383 cycle_A: 4.084 idt_A: 0.337 D_B: 0.085 G_B: 0.450 cycle_B: 0.999 idt_B: 1.159 \n",
            "End of epoch 39 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 40, iters: 100, time: 2.136, data: 0.609) D_A: 0.161 G_A: 0.243 cycle_A: 2.475 idt_A: 0.335 D_B: 0.225 G_B: 0.140 cycle_B: 0.940 idt_B: 0.991 \n",
            "(epoch: 40, iters: 200, time: 1.406, data: 0.002) D_A: 0.244 G_A: 0.298 cycle_A: 1.148 idt_A: 0.316 D_B: 0.062 G_B: 0.259 cycle_B: 0.917 idt_B: 0.367 \n",
            "(epoch: 40, iters: 300, time: 1.403, data: 0.002) D_A: 0.150 G_A: 0.558 cycle_A: 1.538 idt_A: 0.286 D_B: 0.138 G_B: 0.304 cycle_B: 0.897 idt_B: 0.882 \n",
            "(epoch: 40, iters: 400, time: 1.406, data: 0.002) D_A: 0.124 G_A: 0.630 cycle_A: 1.789 idt_A: 0.284 D_B: 0.159 G_B: 0.431 cycle_B: 0.815 idt_B: 0.864 \n",
            "(epoch: 40, iters: 500, time: 2.079, data: 0.002) D_A: 0.214 G_A: 0.797 cycle_A: 2.320 idt_A: 0.277 D_B: 0.111 G_B: 0.643 cycle_B: 0.824 idt_B: 0.944 \n",
            "saving the latest model (epoch 40, total_iters 20000)\n",
            "saving the model at the end of epoch 40, iters 20000\n",
            "End of epoch 40 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 41, iters: 100, time: 1.405, data: 0.117) D_A: 0.159 G_A: 0.393 cycle_A: 1.087 idt_A: 0.286 D_B: 0.113 G_B: 0.623 cycle_B: 0.881 idt_B: 0.404 \n",
            "(epoch: 41, iters: 200, time: 1.407, data: 0.002) D_A: 0.158 G_A: 0.479 cycle_A: 1.255 idt_A: 0.281 D_B: 0.229 G_B: 0.241 cycle_B: 0.888 idt_B: 0.355 \n",
            "(epoch: 41, iters: 300, time: 1.410, data: 0.002) D_A: 0.164 G_A: 0.860 cycle_A: 1.318 idt_A: 0.292 D_B: 0.262 G_B: 0.219 cycle_B: 0.880 idt_B: 0.647 \n",
            "(epoch: 41, iters: 400, time: 2.095, data: 0.002) D_A: 0.151 G_A: 0.462 cycle_A: 1.216 idt_A: 0.298 D_B: 0.210 G_B: 0.209 cycle_B: 0.900 idt_B: 0.403 \n",
            "(epoch: 41, iters: 500, time: 1.407, data: 0.002) D_A: 0.114 G_A: 0.531 cycle_A: 3.023 idt_A: 0.283 D_B: 0.343 G_B: 0.673 cycle_B: 0.822 idt_B: 1.042 \n",
            "End of epoch 41 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 42, iters: 100, time: 1.400, data: 0.143) D_A: 0.111 G_A: 0.338 cycle_A: 1.194 idt_A: 0.277 D_B: 0.291 G_B: 0.084 cycle_B: 0.831 idt_B: 0.569 \n",
            "(epoch: 42, iters: 200, time: 1.398, data: 0.002) D_A: 0.129 G_A: 0.581 cycle_A: 1.150 idt_A: 0.299 D_B: 0.104 G_B: 0.601 cycle_B: 0.892 idt_B: 0.447 \n",
            "(epoch: 42, iters: 300, time: 2.086, data: 0.002) D_A: 0.105 G_A: 0.814 cycle_A: 2.709 idt_A: 0.298 D_B: 0.155 G_B: 0.182 cycle_B: 0.939 idt_B: 1.028 \n",
            "(epoch: 42, iters: 400, time: 1.399, data: 0.002) D_A: 0.101 G_A: 0.508 cycle_A: 1.199 idt_A: 0.282 D_B: 0.242 G_B: 0.551 cycle_B: 0.880 idt_B: 0.520 \n",
            "(epoch: 42, iters: 500, time: 1.402, data: 0.002) D_A: 0.096 G_A: 0.441 cycle_A: 2.476 idt_A: 0.311 D_B: 0.171 G_B: 0.241 cycle_B: 0.906 idt_B: 0.739 \n",
            "End of epoch 42 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 43, iters: 100, time: 1.402, data: 0.129) D_A: 0.076 G_A: 0.496 cycle_A: 1.130 idt_A: 0.304 D_B: 0.157 G_B: 0.293 cycle_B: 0.864 idt_B: 0.641 \n",
            "(epoch: 43, iters: 200, time: 2.189, data: 0.002) D_A: 0.090 G_A: 1.001 cycle_A: 1.658 idt_A: 0.293 D_B: 0.105 G_B: 0.481 cycle_B: 0.944 idt_B: 0.425 \n",
            "(epoch: 43, iters: 300, time: 1.404, data: 0.002) D_A: 0.061 G_A: 0.818 cycle_A: 1.393 idt_A: 0.306 D_B: 0.036 G_B: 0.664 cycle_B: 0.918 idt_B: 0.504 \n",
            "(epoch: 43, iters: 400, time: 1.397, data: 0.002) D_A: 0.054 G_A: 0.600 cycle_A: 1.475 idt_A: 0.312 D_B: 0.126 G_B: 0.468 cycle_B: 0.969 idt_B: 0.642 \n",
            "(epoch: 43, iters: 500, time: 1.408, data: 0.002) D_A: 0.038 G_A: 1.178 cycle_A: 1.258 idt_A: 0.301 D_B: 0.243 G_B: 0.197 cycle_B: 0.916 idt_B: 0.573 \n",
            "End of epoch 43 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 44, iters: 100, time: 2.092, data: 0.146) D_A: 0.030 G_A: 0.712 cycle_A: 1.631 idt_A: 0.559 D_B: 0.069 G_B: 0.537 cycle_B: 0.919 idt_B: 0.673 \n",
            "(epoch: 44, iters: 200, time: 1.401, data: 0.002) D_A: 0.085 G_A: 0.856 cycle_A: 1.228 idt_A: 0.308 D_B: 0.127 G_B: 0.651 cycle_B: 0.919 idt_B: 0.525 \n",
            "(epoch: 44, iters: 300, time: 1.397, data: 0.002) D_A: 0.064 G_A: 0.599 cycle_A: 2.540 idt_A: 0.300 D_B: 0.151 G_B: 0.545 cycle_B: 0.905 idt_B: 1.272 \n",
            "(epoch: 44, iters: 400, time: 1.401, data: 0.002) D_A: 0.038 G_A: 0.816 cycle_A: 0.928 idt_A: 0.294 D_B: 0.141 G_B: 0.385 cycle_B: 0.877 idt_B: 0.285 \n",
            "(epoch: 44, iters: 500, time: 2.140, data: 0.002) D_A: 0.042 G_A: 0.743 cycle_A: 1.695 idt_A: 0.299 D_B: 0.255 G_B: 0.110 cycle_B: 0.933 idt_B: 0.833 \n",
            "End of epoch 44 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 45, iters: 100, time: 1.400, data: 0.163) D_A: 0.028 G_A: 0.818 cycle_A: 1.181 idt_A: 0.284 D_B: 0.139 G_B: 0.352 cycle_B: 0.886 idt_B: 0.388 \n",
            "(epoch: 45, iters: 200, time: 1.406, data: 0.002) D_A: 0.048 G_A: 0.674 cycle_A: 1.451 idt_A: 0.293 D_B: 0.163 G_B: 0.340 cycle_B: 0.941 idt_B: 0.548 \n",
            "(epoch: 45, iters: 300, time: 1.401, data: 0.002) D_A: 0.027 G_A: 1.003 cycle_A: 1.086 idt_A: 0.283 D_B: 0.104 G_B: 0.402 cycle_B: 0.874 idt_B: 0.501 \n",
            "(epoch: 45, iters: 400, time: 2.148, data: 0.002) D_A: 0.012 G_A: 0.982 cycle_A: 1.446 idt_A: 0.286 D_B: 0.122 G_B: 0.498 cycle_B: 0.862 idt_B: 0.595 \n",
            "(epoch: 45, iters: 500, time: 1.400, data: 0.002) D_A: 0.019 G_A: 0.868 cycle_A: 2.035 idt_A: 0.287 D_B: 0.105 G_B: 0.477 cycle_B: 0.899 idt_B: 0.984 \n",
            "saving the model at the end of epoch 45, iters 22500\n",
            "End of epoch 45 / 200 \t Time Taken: 661 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 46, iters: 100, time: 1.400, data: 0.156) D_A: 0.018 G_A: 0.903 cycle_A: 1.364 idt_A: 0.285 D_B: 0.248 G_B: 0.516 cycle_B: 0.875 idt_B: 0.446 \n",
            "(epoch: 46, iters: 200, time: 1.408, data: 0.002) D_A: 0.046 G_A: 0.799 cycle_A: 2.211 idt_A: 0.285 D_B: 0.157 G_B: 0.219 cycle_B: 0.902 idt_B: 0.972 \n",
            "(epoch: 46, iters: 300, time: 2.152, data: 0.002) D_A: 0.025 G_A: 1.080 cycle_A: 1.576 idt_A: 0.286 D_B: 0.076 G_B: 0.365 cycle_B: 0.879 idt_B: 0.820 \n",
            "(epoch: 46, iters: 400, time: 1.403, data: 0.002) D_A: 0.029 G_A: 0.881 cycle_A: 1.355 idt_A: 0.277 D_B: 0.127 G_B: 0.478 cycle_B: 0.840 idt_B: 0.431 \n",
            "(epoch: 46, iters: 500, time: 1.399, data: 0.002) D_A: 0.057 G_A: 0.590 cycle_A: 1.498 idt_A: 0.299 D_B: 0.097 G_B: 0.516 cycle_B: 1.087 idt_B: 0.549 \n",
            "End of epoch 46 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 47, iters: 100, time: 1.400, data: 0.129) D_A: 0.066 G_A: 0.858 cycle_A: 2.150 idt_A: 0.279 D_B: 0.175 G_B: 0.382 cycle_B: 0.874 idt_B: 0.917 \n",
            "(epoch: 47, iters: 200, time: 2.145, data: 0.002) D_A: 0.041 G_A: 0.878 cycle_A: 2.201 idt_A: 0.276 D_B: 0.117 G_B: 0.409 cycle_B: 0.847 idt_B: 0.779 \n",
            "(epoch: 47, iters: 300, time: 1.396, data: 0.002) D_A: 0.327 G_A: 0.980 cycle_A: 1.109 idt_A: 0.294 D_B: 0.206 G_B: 0.283 cycle_B: 0.884 idt_B: 0.315 \n",
            "(epoch: 47, iters: 400, time: 1.395, data: 0.002) D_A: 0.207 G_A: 0.349 cycle_A: 1.642 idt_A: 0.276 D_B: 0.113 G_B: 0.582 cycle_B: 0.851 idt_B: 0.794 \n",
            "(epoch: 47, iters: 500, time: 1.403, data: 0.002) D_A: 0.185 G_A: 0.523 cycle_A: 1.214 idt_A: 0.286 D_B: 0.234 G_B: 0.592 cycle_B: 0.868 idt_B: 0.702 \n",
            "End of epoch 47 / 200 \t Time Taken: 659 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 48, iters: 100, time: 2.163, data: 0.140) D_A: 0.139 G_A: 0.174 cycle_A: 1.127 idt_A: 0.275 D_B: 0.210 G_B: 0.649 cycle_B: 0.835 idt_B: 0.506 \n",
            "(epoch: 48, iters: 200, time: 1.408, data: 0.002) D_A: 0.053 G_A: 0.590 cycle_A: 1.465 idt_A: 0.271 D_B: 0.283 G_B: 0.506 cycle_B: 0.827 idt_B: 0.452 \n",
            "(epoch: 48, iters: 300, time: 1.404, data: 0.002) D_A: 0.041 G_A: 0.795 cycle_A: 1.821 idt_A: 0.271 D_B: 0.083 G_B: 0.437 cycle_B: 0.847 idt_B: 0.631 \n",
            "(epoch: 48, iters: 400, time: 1.405, data: 0.002) D_A: 0.045 G_A: 0.612 cycle_A: 2.138 idt_A: 0.288 D_B: 0.127 G_B: 0.126 cycle_B: 0.901 idt_B: 0.899 \n",
            "(epoch: 48, iters: 500, time: 2.183, data: 0.003) D_A: 0.038 G_A: 0.819 cycle_A: 2.390 idt_A: 0.278 D_B: 0.157 G_B: 0.420 cycle_B: 0.823 idt_B: 0.548 \n",
            "End of epoch 48 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 49, iters: 100, time: 1.403, data: 0.120) D_A: 0.022 G_A: 0.832 cycle_A: 2.012 idt_A: 0.284 D_B: 0.146 G_B: 0.234 cycle_B: 0.865 idt_B: 0.621 \n",
            "(epoch: 49, iters: 200, time: 1.405, data: 0.002) D_A: 0.023 G_A: 0.853 cycle_A: 3.585 idt_A: 0.285 D_B: 0.152 G_B: 0.575 cycle_B: 0.858 idt_B: 0.975 \n",
            "(epoch: 49, iters: 300, time: 1.403, data: 0.002) D_A: 0.032 G_A: 0.726 cycle_A: 2.108 idt_A: 0.280 D_B: 0.201 G_B: 0.213 cycle_B: 0.860 idt_B: 0.728 \n",
            "(epoch: 49, iters: 400, time: 2.199, data: 0.002) D_A: 0.018 G_A: 0.716 cycle_A: 1.342 idt_A: 0.294 D_B: 0.239 G_B: 0.540 cycle_B: 0.882 idt_B: 0.474 \n",
            "(epoch: 49, iters: 500, time: 1.401, data: 0.002) D_A: 0.021 G_A: 0.912 cycle_A: 1.848 idt_A: 0.271 D_B: 0.056 G_B: 0.576 cycle_B: 0.825 idt_B: 0.465 \n",
            "End of epoch 49 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 50, iters: 100, time: 1.399, data: 0.140) D_A: 0.025 G_A: 0.812 cycle_A: 1.560 idt_A: 0.278 D_B: 0.073 G_B: 0.457 cycle_B: 0.883 idt_B: 0.483 \n",
            "(epoch: 50, iters: 200, time: 1.409, data: 0.003) D_A: 0.039 G_A: 0.868 cycle_A: 2.908 idt_A: 0.278 D_B: 0.078 G_B: 0.421 cycle_B: 0.862 idt_B: 1.282 \n",
            "(epoch: 50, iters: 300, time: 2.225, data: 0.002) D_A: 0.023 G_A: 0.787 cycle_A: 2.110 idt_A: 0.285 D_B: 0.260 G_B: 0.323 cycle_B: 0.890 idt_B: 0.775 \n",
            "(epoch: 50, iters: 400, time: 1.404, data: 0.003) D_A: 0.027 G_A: 0.801 cycle_A: 1.322 idt_A: 0.284 D_B: 0.079 G_B: 0.414 cycle_B: 0.925 idt_B: 0.437 \n",
            "(epoch: 50, iters: 500, time: 1.403, data: 0.002) D_A: 0.018 G_A: 0.714 cycle_A: 1.558 idt_A: 0.284 D_B: 0.073 G_B: 0.587 cycle_B: 0.853 idt_B: 0.436 \n",
            "saving the latest model (epoch 50, total_iters 25000)\n",
            "saving the model at the end of epoch 50, iters 25000\n",
            "End of epoch 50 / 200 \t Time Taken: 664 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 51, iters: 100, time: 1.399, data: 0.157) D_A: 0.034 G_A: 1.210 cycle_A: 3.866 idt_A: 0.273 D_B: 0.084 G_B: 0.571 cycle_B: 0.863 idt_B: 1.568 \n",
            "(epoch: 51, iters: 200, time: 2.225, data: 0.002) D_A: 0.037 G_A: 0.954 cycle_A: 1.181 idt_A: 0.273 D_B: 0.196 G_B: 0.368 cycle_B: 0.831 idt_B: 0.444 \n",
            "(epoch: 51, iters: 300, time: 1.410, data: 0.002) D_A: 0.055 G_A: 0.668 cycle_A: 2.228 idt_A: 0.281 D_B: 0.138 G_B: 0.341 cycle_B: 0.861 idt_B: 0.814 \n",
            "(epoch: 51, iters: 400, time: 1.411, data: 0.002) D_A: 0.058 G_A: 1.164 cycle_A: 1.121 idt_A: 0.272 D_B: 0.072 G_B: 0.258 cycle_B: 0.861 idt_B: 0.412 \n",
            "(epoch: 51, iters: 500, time: 1.410, data: 0.002) D_A: 0.037 G_A: 0.966 cycle_A: 1.914 idt_A: 0.283 D_B: 0.104 G_B: 0.150 cycle_B: 0.838 idt_B: 0.673 \n",
            "End of epoch 51 / 200 \t Time Taken: 660 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "(epoch: 52, iters: 100, time: 2.251, data: 0.125) D_A: 0.046 G_A: 0.612 cycle_A: 1.945 idt_A: 0.270 D_B: 0.268 G_B: 0.199 cycle_B: 0.823 idt_B: 0.616 \n",
            "(epoch: 52, iters: 200, time: 1.405, data: 0.003) D_A: 0.090 G_A: 0.468 cycle_A: 2.281 idt_A: 0.273 D_B: 0.188 G_B: 0.266 cycle_B: 0.845 idt_B: 1.256 \n",
            "(epoch: 52, iters: 300, time: 1.415, data: 0.002) D_A: 0.020 G_A: 0.815 cycle_A: 1.003 idt_A: 0.261 D_B: 0.220 G_B: 0.263 cycle_B: 0.839 idt_B: 0.322 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQQmFgqX-Oci",
        "outputId": "a417fb16-8c10-4474-c980-310caa86f3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MChGYNg-hWy",
        "outputId": "1b8fc303-cff0-4b8d-c439-61c8f74982b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd drive/MyDrive/pytorch-CycleGAN-and-pix2pix/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-ppH09zk9eX",
        "outputId": "76471fa9-287d-4d7b-b88d-6cfcce47eb6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os, os.path\n",
        "\n",
        "# simple version for working with CWD\n",
        "DIR = './datasets/vangogh2photo/trainA'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model test --no_dropout`\n",
        "\n",
        "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
        "\n",
        "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsKkEq0yGh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f622d5-2efe-4ba5-f8fd-3a2797a63be0"
      },
      "source": [
        "!python test.py --dataroot datasets/vangogh2photo/testA --name vangogh2photo --model test --no_dropout"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: datasets/vangogh2photo/testA  \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: vangogh2photo                 \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/vangogh2photo/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory ./results/vangogh2photo/test_latest\n",
            "processing (0000)-th image... ['datasets/vangogh2photo/testA/IMG_20191113_160658.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mgg8raPyizq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G3oVH9DyqLQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}